{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff8b95d-d919-40df-acec-48eb075d7c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NOTE: This code can be downloaded from https://github.com/vv2246/tr-dag-cycles\n",
    "sys.path.append(\"../../tr-dag-cycles/\")\n",
    "from cycle_utilities import tr\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "from utils import read_data\n",
    "from encapsulation_dag import encapsulation_dag\n",
    "from layer_randomization import layer_randomization\n",
    "\n",
    "from matplotlib import gridspec\n",
    "import matplotlib_defaults\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89fe9aa-9e18-4fe1-bb71-d6c03f6eb43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dag_heights(dag):\n",
    "    # transitiviely reduce the DAG\n",
    "    dag_tr = tr(dag.copy())\n",
    "    heights_dist = []\n",
    "    heights_by_node = defaultdict(list)\n",
    "    # Get all of the nodes that have no in-degree and non-zero out-degree\n",
    "    root_nodes = [node for node in dag_tr.nodes() if dag_tr.out_degree(node) > 0 and dag_tr.in_degree(node) == 0]\n",
    "    for source in root_nodes:\n",
    "        sp_dict = nx.single_source_shortest_path_length(dag_tr, source)\n",
    "        for target in sp_dict:\n",
    "            if source == target:\n",
    "                continue\n",
    "            heights_dist.append(sp_dict[target])\n",
    "            heights_by_node[source].append(sp_dict[target])\n",
    "    return heights_dist, heights_by_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471cd604-ff9b-4ec6-ac5c-1f7af36bc40e",
   "metadata": {},
   "source": [
    "Note that this notebook relies on running once with read_height_distribution = False to generate the data, which will take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd48dd-e2ef-474a-b6c9-dc5b77c47d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "datasets = [\"email-Enron\", \"contact-primary-school\", \"contact-high-school\", \"coauth-MAG-History\", \"coauth-MAG-Geology\", \"coauth-DBLP\"]\n",
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da31866-736e-4572-890e-5ddced8bf61b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "read_height_distributions = True\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    if not read_height_distributions:\n",
    "        observed_path = data_dir + dataset + \"/\" + dataset + \"-\" \n",
    "        print(\"Reading hyperedges.\")\n",
    "        hyperedges = read_data(observed_path, multiedges=False)\n",
    "\n",
    "        print(\"Computing observed dag.\")\n",
    "        obs_dag, obs_nth, obs_he_map = encapsulation_dag(hyperedges)\n",
    "\n",
    "        print(f\"Dag edges: {obs_dag.number_of_edges()}\")\n",
    "\n",
    "        # Observed\n",
    "        dag = obs_dag\n",
    "        print(\"Computing observed dag heights.\")\n",
    "        observed_heights, obs_node_heights = compute_dag_heights(dag.copy())\n",
    "        height_output_file = data_dir + dataset + f\"/{dataset}_dag_heights.txt\"\n",
    "        with open(height_output_file, \"w\") as fout:\n",
    "            fout.write(\",\".join(map(str,observed_heights)))\n",
    "        print(f\"Observed dag average height: {np.mean(observed_heights)}\")\n",
    "\n",
    "        obs_node_heights_file = data_dir + dataset + f\"/{dataset}_dag_heights_by_node.pickle\"\n",
    "        with open(obs_node_heights_file, \"wb\") as fpickle:\n",
    "            pickle.dump(obs_node_heights, fpickle)\n",
    "\n",
    "        # Random\n",
    "        random_heights = []\n",
    "        for _ in range(num_samples):\n",
    "            print(\"Computing layer randomization.\")\n",
    "            random_hyperedges = layer_randomization(hyperedges)\n",
    "            #### Heights ####\n",
    "            print(\"Computing random dag.\")\n",
    "            random_dag, _, _ = encapsulation_dag(random_hyperedges)\n",
    "            print(f\"Random dag has {random_dag.number_of_edges()} edges.\")\n",
    "            print(\"Computing random dag heights.\")\n",
    "            sample_heights, random_node_heights = compute_dag_heights(random_dag.copy())\n",
    "            random_heights.append(sample_heights)\n",
    "            print(f\"Random dag average height: {np.mean(sample_heights)}\")\n",
    "\n",
    "        height_output_file = data_dir + dataset + f\"/{dataset}_layer_randomization_dag_heights.txt\"\n",
    "        with open(height_output_file, \"w\") as fout:\n",
    "            for sample_heights in random_heights:\n",
    "                fout.write(\",\".join(map(str,sample_heights)) + \"\\n\")\n",
    "    else:\n",
    "        # Get observed and random heights from files\n",
    "        with open(data_dir + dataset + \"/\" + dataset + \"_dag_heights.txt\", 'r') as fin:\n",
    "            observed_heights = np.array(list(map(int, fin.readline().split(','))))\n",
    "\n",
    "        with open(data_dir + dataset + \"/\" + dataset + \"_layer_randomization_dag_heights.txt\", 'r') as fin:\n",
    "            random_heights = []\n",
    "            for line in fin:\n",
    "                random_heights.append(np.array(list(map(int, line.split(',')))))\n",
    "\n",
    "        with open(data_dir + dataset + \"/\" + dataset + \"_dag_heights_by_node.pickle\", \"rb\") as fpickle:\n",
    "            obs_node_heights = pickle.load(fpickle)\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3700d527-af6f-4d0c-9e27-664e001458b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_height_data(dataset, data_dir=\"../data/\"):\n",
    "    dataset_info = dict()\n",
    "    # Compute observed DAG\n",
    "    observed_path = data_dir + dataset + \"/\" + dataset + \"-\" \n",
    "    hyperedges = read_data(observed_path, multiedges=False)\n",
    "    obs_dag, obs_nth, obs_he_map = encapsulation_dag(hyperedges)\n",
    "    dataset_info[\"obs_dag\"] = obs_dag\n",
    "    # Read heights by node dict\n",
    "    with open(data_dir + dataset + \"/\" + dataset + \"_dag_heights_by_node.pickle\", \"rb\") as fpickle:\n",
    "        obs_node_heights = pickle.load(fpickle)\n",
    "    dataset_info[\"observed_node_heights\"] = obs_node_heights\n",
    "    \n",
    "    # Get a random DAG\n",
    "    random_hyperedges = layer_randomization(hyperedges)\n",
    "    random_dag, _, _ = encapsulation_dag(random_hyperedges)\n",
    "    dataset_info[\"random_dag\"] = random_dag\n",
    "    \n",
    "    # Get observed and random heights from files\n",
    "    with open(data_dir + dataset + \"/\" + dataset + \"_dag_heights.txt\", 'r') as fin:\n",
    "        observed_heights = np.array(list(map(int, fin.readline().split(','))))\n",
    "    dataset_info[\"observed_heights\"] = observed_heights\n",
    "\n",
    "    with open(data_dir + dataset + \"/\" + dataset + \"_layer_randomization_dag_heights.txt\", 'r') as fin:\n",
    "        random_heights = []\n",
    "        for line in fin:\n",
    "            random_heights.append(np.array(list(map(int, line.split(',')))))\n",
    "    dataset_info[\"random_heights\"] = random_heights\n",
    "    \n",
    "    # Get averages of random count distributions\n",
    "    random_count_dists = dict()\n",
    "    for arr in random_heights:\n",
    "        arr_counts = dict(Counter(arr))\n",
    "        for key in arr_counts:\n",
    "            if key in random_count_dists:\n",
    "                random_count_dists[key].append(arr_counts[key])\n",
    "            else:\n",
    "                random_count_dists[key] = [arr_counts[key]]\n",
    "\n",
    "    dataset_info[\"random_count_dists\"] = random_count_dists\n",
    "    \n",
    "    random_means = dict()\n",
    "    random_stds = dict()\n",
    "    for key in random_count_dists:\n",
    "        random_means[key] = np.mean(random_count_dists[key])\n",
    "        random_stds[key] = np.std(random_count_dists[key])\n",
    "\n",
    "    # Fill in missing values from both counters\n",
    "    observed_counts = dict(Counter(observed_heights))\n",
    "    for c in set(observed_counts.keys()).union(set(random_means.keys())):\n",
    "        if c not in random_means:\n",
    "            random_means[c] = 0\n",
    "            random_stds[c] = 0\n",
    "\n",
    "        if c not in observed_counts:\n",
    "            observed_counts[c] = 0\n",
    "\n",
    "    dataset_info[\"observed_counts\"] = observed_counts\n",
    "    dataset_info[\"random_means\"] = random_means\n",
    "    dataset_info[\"random_stds\"] = random_stds\n",
    "    _, random_node_heights = compute_dag_heights(random_dag.copy())\n",
    "    dataset_info[\"random_node_heights\"] = random_node_heights\n",
    "    for normalized in [True, False]:\n",
    "        for key, heights_by_node, dag in [(\"obs\", obs_node_heights, obs_dag),\n",
    "                                               (\"rnd\", random_node_heights, random_dag)]:\n",
    "\n",
    "            # Compute DAG out-degree vs maximum height for all roots\n",
    "            x = np.zeros(len(heights_by_node))\n",
    "            y = np.zeros(len(heights_by_node))\n",
    "            colors = np.zeros(len(heights_by_node))\n",
    "            for idx, node in enumerate(heights_by_node):\n",
    "                deg = len(list(dag.successors(node)))\n",
    "                if not normalized:\n",
    "                    x[idx] = deg\n",
    "                    y[idx] = np.max(heights_by_node[node])\n",
    "                else:\n",
    "                    x[idx] = deg / (2**len(node)-2)\n",
    "                    y[idx] = np.max(heights_by_node[node]) / (len(node)-1)              \n",
    "                colors[idx] = deg\n",
    "            # Sort by colors\n",
    "            sorted_indices = np.argsort(colors)\n",
    "            x = x[sorted_indices]\n",
    "            y = y[sorted_indices]\n",
    "            colors = colors[sorted_indices]\n",
    "            if not normalized:\n",
    "                dataset_info[key + \"_x\"] = list(x)\n",
    "                dataset_info[key + \"_y\"] = list(y)\n",
    "                dataset_info[key + \"_colors\"] = list(colors)\n",
    "            else:\n",
    "                dataset_info[key + \"_x_normed\"] = list(x)\n",
    "                dataset_info[key + \"_y_normed\"] = list(y)\n",
    "                dataset_info[key + \"_colors_normed\"] = list(colors)\n",
    "    return dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec00c02-1d98-4487-8500-f13b29e28d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"coauth-MAG-Geology\", \"coauth-MAG-History\",  \"contact-high-school\", \"contact-primary-school\", \"email-Enron\", \"email-Eu\"]\n",
    "dataset_info_dicts = dict()\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    dataset_info_dicts[dataset] = read_height_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aba7a1-c1ca-4952-a123-dba7c275a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(56, 10), tight_layout=True)\n",
    "\n",
    "title_size=16\n",
    "inset_title_size=14\n",
    "axis_label_size=16\n",
    "tick_label_sizes=7\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = tick_label_sizes\n",
    "plt.rcParams['xtick.labelsize'] = tick_label_sizes\n",
    "\n",
    "gs = gridspec.GridSpec(3, len(datasets)*2)\n",
    "for col, dataset in enumerate(datasets):\n",
    "    # Get the data\n",
    "    obs_node_heights = dataset_info_dicts[dataset][\"observed_node_heights\"]\n",
    "    random_node_heights = dataset_info_dicts[dataset][\"random_node_heights\"]\n",
    "    observed_counts = dataset_info_dicts[dataset][\"observed_counts\"]\n",
    "    random_means = dataset_info_dicts[dataset][\"random_means\"]\n",
    "    random_stds = dataset_info_dicts[dataset][\"random_stds\"]\n",
    "    \n",
    "    # Initialize row to 0 and get relevent axis\n",
    "    row = 0\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    \n",
    "    # Plot the histograms of DAG heights\n",
    "    bar_width=0.15\n",
    "    x = np.array(list(observed_counts.keys())) - (bar_width / 2)\n",
    "    ax.bar(x, observed_counts.values(), width=bar_width, label=\"Observed\")\n",
    "\n",
    "    x = np.array(list(observed_counts.keys())) + (bar_width / 2)\n",
    "    ax.bar(x, random_means.values(), yerr=random_stds.values(), width=bar_width, label=\"Random\")\n",
    "\n",
    "    ax.set(yscale='symlog', xlabel=\"Height\", ylabel=\"Frequency\", xlim=(-0.01, 9), xticks=list(range(1, 10)))\n",
    "    if col == 0:\n",
    "        ax.legend(frameon=False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_title(dataset, {\"fontsize\":title_size})\n",
    "    \n",
    "    # Plot the scatter plots of degree vs height\n",
    "    for normalized in [False, True]:\n",
    "        row += 1\n",
    "        gs_nested = gridspec.GridSpecFromSubplotSpec(nrows=1, ncols=2, subplot_spec=gs[row, col])\n",
    "        max_ys = []\n",
    "        max_xs = []\n",
    "        nested_col = 0\n",
    "        for name, heights_by_node in [(\"obs\", obs_node_heights),\n",
    "                                           (\"rnd\", random_node_heights)]:\n",
    "\n",
    "            if name == \"obs\":\n",
    "                ax = fig.add_subplot(gs_nested[0, nested_col])\n",
    "            else:\n",
    "                ax = fig.add_subplot(gs_nested[0, nested_col], sharey=ax)\n",
    "\n",
    "            nested_col += 1\n",
    "            \n",
    "            suffix = \"\"\n",
    "            if normalized:\n",
    "                suffix = \"_normed\"\n",
    "\n",
    "            x = dataset_info_dicts[dataset][name + \"_x\" + suffix]\n",
    "            y = dataset_info_dicts[dataset][name + \"_y\" + suffix]\n",
    "            colors = dataset_info_dicts[dataset][name + \"_colors\" + suffix]\n",
    "            ax.scatter(x, y, c=colors, cmap='viridis', rasterized=True)\n",
    "            \n",
    "            # Axis labels\n",
    "            if not normalized:\n",
    "                ax.set_xlabel(r\"$d_{\\mathrm{dag}}$\", fontsize=axis_label_size)\n",
    "                if name == \"obs\":\n",
    "                    ax.set_ylabel(r\"$\\max(h)$\", fontsize=axis_label_size)\n",
    "            elif normalized:\n",
    "                ax.set_xlabel(r\"$\\frac{d_{\\mathrm{dag}}}{2^k - 2}$\", fontsize=axis_label_size)\n",
    "                if name == \"obs\":\n",
    "                    ax.set_ylabel(r\"$\\frac{\\max(h)}{k-1}$\", fontsize=axis_label_size)\n",
    "\n",
    "            max_ys.append(int(max(y)))\n",
    "            max_xs.append(int(max(x)))\n",
    "\n",
    "            if normalized:\n",
    "                ax.set_xticks([0.0, 0.25, 0.5, 0.75, 1.0], size=7)\n",
    "                ax.set_yticks([0.0, 0.25, 0.5, 0.75, 1.0], size=7)\n",
    "            else:\n",
    "                ax.set(ylim=(-0.1, max(max_ys)+1), xlim=(-0.1, max(max_xs)+1))\n",
    "                ax.set_yticks(list(range(2, max(max_ys)+1, 1)))\n",
    "                ax.xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "                if name == \"obs\":\n",
    "                    ax.set_title(f\"Observed\\n({len(obs_node_heights)} roots)\", size=inset_title_size)\n",
    "                else:\n",
    "                    ax.set_title(f\"Layer Randomization\\n({len(random_node_heights)} roots)\", size=inset_title_size)\n",
    "\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "\n",
    "fig.subplots_adjust(wspace=0.9, hspace=0.3)\n",
    "#fig.savefig(\"../results/plots/dag_analysis.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db133b33-d667-487f-8243-d5c5370496b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
